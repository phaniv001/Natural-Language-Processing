{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = [['Hello', 'this', 'is', 'python', 'training', 'by', 'Aman'],\n",
    "                     ['Hello', 'this', 'is', 'java', 'training', 'by', 'Aman'],\n",
    "                     ['Hello', 'this', 'is', 'Data Science', 'training', 'by', 'unfold', 'Data', 'science'],\n",
    "                     ['Hello', 'this', 'is', 'programming', 'training', '']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training word2vec\n",
    "\n",
    "mymodel = Word2Vec(tokenized_sentence, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'this', 'is', 'python', 'training', 'by', 'Aman', 'java', 'Data Science', 'unfold', 'Data', 'science', 'programming', '']\n"
     ]
    }
   ],
   "source": [
    "words = list(mymodel.wv.vocab)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00301687  0.00264102  0.00319383  0.00228811  0.00299492  0.00480412\n",
      " -0.00101683  0.00412398 -0.00389662 -0.00450724 -0.00482626 -0.00117881\n",
      " -0.00460529 -0.00115099  0.00114765 -0.00457821  0.00231652 -0.00265483\n",
      "  0.00368051 -0.00090518  0.00245863  0.00055421 -0.0036428  -0.00218155\n",
      " -0.00087151  0.0003536   0.00088714  0.00206593 -0.00297591 -0.00109891\n",
      " -0.00130623  0.00185955  0.00226752  0.00097536 -0.00099665  0.00355611\n",
      "  0.004166   -0.00343716  0.00355046 -0.00184526  0.00259758 -0.00131937\n",
      " -0.00052313  0.00400841  0.00095502  0.00442086 -0.00359578  0.00171602\n",
      " -0.00460347  0.00284757 -0.00235986  0.00399665 -0.00135034  0.00148057\n",
      " -0.00450972 -0.00179162 -0.00263197  0.00180473 -0.00281323  0.00250759\n",
      "  0.00489149  0.00464239  0.00300893  0.00181023  0.00272141 -0.00060971\n",
      " -0.00455504  0.00168438 -0.00336344 -0.00060874  0.00171925 -0.00462814\n",
      " -0.00109115 -0.00478454 -0.00065295 -0.00144504  0.00437326  0.00263299\n",
      "  0.00214796 -0.00220037  0.00027245  0.00056722 -0.00327155  0.00026744\n",
      "  0.00499068 -0.00486933 -0.00489747  0.00292538  0.00395816 -0.00340184\n",
      "  0.00389873  0.00211791  0.00190209 -0.00438151 -0.0011007  -0.0028187\n",
      "  0.00171999 -0.00420766 -0.00428807  0.00056697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3b9cac13c222>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  print(mymodel['Hello'])\n"
     ]
    }
   ],
   "source": [
    "print(mymodel['Hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 0.17398984730243683),\n",
       " ('by', 0.09012329578399658),\n",
       " ('this', 0.03842597082257271),\n",
       " ('Data Science', 0.02923613414168358),\n",
       " ('science', 0.023316582664847374),\n",
       " ('unfold', -0.014441132545471191),\n",
       " ('java', -0.027739744633436203),\n",
       " ('is', -0.04176836460828781),\n",
       " ('programming', -0.05720347911119461),\n",
       " ('Aman', -0.0662764310836792)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.wv.most_similar('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embedding using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['hello, how are you',\n",
    "       'how are you',\n",
    "       'how are you doing',\n",
    "       'I am doing great',\n",
    "       'I am doing good',\n",
    "       'I am good']\n",
    "\n",
    "sent_labels = [1,1,1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 8, 5, 15], [8, 5, 15], [8, 5, 15, 9], [10, 29, 9, 20], [10, 29, 9, 20], [10, 29, 20]]\n"
     ]
    }
   ],
   "source": [
    "my_vocab_size = 30\n",
    "encoded_sent = [one_hot(i, my_vocab_size) for i in sent]\n",
    "print(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 14  8  5 15]\n",
      " [ 0  0  8  5 15]\n",
      " [ 0  8  5 15  9]\n",
      " [ 0 10 29  9 20]\n",
      " [ 0 10 29  9 20]\n",
      " [ 0  0 10 29 20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 5\n",
    "padded_sent = pad_sequences(encoded_sent, maxlen=length, padding='pre')\n",
    "print(padded_sent)\n",
    "padded_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Sequential()\n",
    "mymodel.add(Embedding(my_vocab_size, 8, input_length = length))\n",
    "mymodel.add(Flatten())\n",
    "mymodel.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6764 - accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6743 - accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6722 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6701 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6658 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6637 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 321us/step - loss: 0.6574 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6532 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6469 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6362 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6340 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6319 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6187 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6165 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6143 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x188b01e3df0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.fit(np.asarray(padded_sent), np.asarray(sent_labels), epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30\n",
    "mysent_to_predict = ['How are you suman', 'I am good']\n",
    "\n",
    "encoded = [one_hot(i,vocab_size)for i in mysent_to_predict]\n",
    "my_padded = pad_sequences(encoded, padding = 'pre', maxlen = length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8,  5, 15,  8],\n",
       "       [ 0,  0, 10, 29, 20]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict_classes(my_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
